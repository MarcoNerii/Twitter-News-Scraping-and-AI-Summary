{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fce42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from zoneinfo import ZoneInfo\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# --- Scraper settings ---\n",
    "USER = \"financialjuice\"          # handle to scrape\n",
    "HOURS_BACK = 24                  # last N hours\n",
    "OUT_TXT = \"financialjuice_last_hours.txt\"\n",
    "OUTPUT_TZ = \"Europe/Zurich\"      # Geneva time\n",
    "MAX_SCROLLS = 80                 # increase for more tweets\n",
    "SCROLL_WAIT_MS = 1600            # increase if loading is slow (e.g., 2000+)\n",
    "COOKIES_FILE = \"x_cookies.json\"  # optional: export your x.com cookies to this file\n",
    "\n",
    "UA = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/124.0 Safari/537.36\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029cb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A browser window opened. Log in to X normally. When your timeline is visible, return here and press Enter.\n",
      "Cookies saved to x_cookies.json\n"
     ]
    }
   ],
   "source": [
    "# Run this ONCE if anonymous scraping yields 0 tweets.\n",
    "# It opens a real browser window. Log in to X, then press Enter in the notebook.\n",
    "async def login_and_save_cookies():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=False, args=[\"--disable-blink-features=AutomationControlled\"]\n",
    "        )\n",
    "        ctx = await browser.new_context(user_agent=UA, viewport={\"width\":1200,\"height\":900})\n",
    "        page = await ctx.new_page()\n",
    "        await page.goto(\"https://x.com/i/flow/login\", wait_until=\"domcontentloaded\", timeout=120_000)\n",
    "        print(\"A browser window opened. Log in to X normally. When your timeline is visible, return here and press Enter.\")\n",
    "        input()\n",
    "        cookies = await ctx.cookies()\n",
    "        with open(COOKIES_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(cookies, f, ensure_ascii=False, indent=2)\n",
    "        await browser.close()\n",
    "        print(f\"Cookies saved to {COOKIES_FILE}\")\n",
    "\n",
    "# Usage (uncomment to run once):\n",
    "# await login_and_save_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ada8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_last_hours(user: str, hours_back: int = 24):\n",
    "    cutoff = datetime.now(timezone.utc) - timedelta(hours=hours_back)\n",
    "    tz = ZoneInfo(OUTPUT_TZ)\n",
    "    rows, seen = [], set()\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        # Chromium is a bit more reliable on X; switch to firefox if you prefer\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=True, args=[\"--disable-blink-features=AutomationControlled\"]\n",
    "        )\n",
    "        ctx = await browser.new_context(user_agent=UA, viewport={\"width\":1280,\"height\":2000})\n",
    "\n",
    "        # Reuse your logged-in session if available (recommended)\n",
    "        if Path(COOKIES_FILE).exists():\n",
    "            try:\n",
    "                with open(COOKIES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "                    await ctx.add_cookies(json.load(f))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        page = await ctx.new_page()\n",
    "        await page.goto(f\"https://x.com/{user}\", wait_until=\"domcontentloaded\", timeout=90_000)\n",
    "\n",
    "        # Try to dismiss consent/overlays (best effort)\n",
    "        for label in (\"Accept\", \"I agree\", \"Allow all\"):\n",
    "            try:\n",
    "                await page.get_by_role(\"button\", name=label).click(timeout=1500)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Scroll & collect\n",
    "        for _ in range(MAX_SCROLLS):\n",
    "            arts = await page.query_selector_all('article[data-testid=\"tweet\"]')\n",
    "            for a in arts:\n",
    "                link_el = await a.query_selector('a[role=\"link\"][href*=\"/status/\"]')\n",
    "                if not link_el:\n",
    "                    continue\n",
    "                href = await link_el.get_attribute(\"href\")\n",
    "                if not href or href in seen:\n",
    "                    continue\n",
    "\n",
    "                t_el = await a.query_selector(\"time\")\n",
    "                if not t_el:\n",
    "                    continue\n",
    "                dt_str = await t_el.get_attribute(\"datetime\")\n",
    "                if not dt_str:\n",
    "                    continue\n",
    "\n",
    "                # parse ISO timestamp (UTC), filter by cutoff\n",
    "                dt = datetime.fromisoformat(dt_str.replace(\"Z\", \"+00:00\"))\n",
    "                if dt < cutoff:\n",
    "                    continue\n",
    "\n",
    "                parts = await a.query_selector_all('[data-testid=\"tweetText\"]')\n",
    "                text = \"\\n\".join([await n.inner_text() for n in parts]).strip() if parts else \"\"\n",
    "\n",
    "                rows.append({\"time\": dt.astimezone(tz), \"text\": text})\n",
    "                seen.add(href)\n",
    "\n",
    "            # scroll for more\n",
    "            await page.mouse.wheel(0, 20000)\n",
    "            await page.wait_for_timeout(SCROLL_WAIT_MS)\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "    # sort newest → oldest & dedupe by (time, text)\n",
    "    out_map = {(r[\"time\"].isoformat(), r[\"text\"]): r for r in rows}\n",
    "    out = list(out_map.values())\n",
    "    out.sort(key=lambda r: r[\"time\"], reverse=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be65939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 245 tweets in last 24h\n",
      "Saved -> financialjuice_last_hours.txt\n"
     ]
    }
   ],
   "source": [
    "rows = await scrape_last_hours(USER, HOURS_BACK)\n",
    "print(f\"Collected {len(rows)} tweets in last {HOURS_BACK}h\")\n",
    "\n",
    "with open(OUT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in rows:\n",
    "        f.write(f\"{r['time'].strftime('%Y-%m-%d %H:%M:%S %Z')} | {r['text']}\\n\\n\")\n",
    "\n",
    "print(f\"Saved -> {OUT_TXT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a350de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from typing import List, Tuple\n",
    "import pathlib\n",
    "\n",
    "# Set your key in the environment before running (e.g., in a terminal: export GOOGLE_API_KEY=\"...\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise RuntimeError(\"Missing GOOGLE_API_KEY environment variable.\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "MODEL_NAME = \"gemini-1.5-flash\"   # or \"gemini-1.5-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55f3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(path: str = \"financialjuice_last_hours.txt\") -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "def chunk_text(s: str, max_chars: int = 15000) -> List[str]:\n",
    "    \"\"\"Greedy chunking by blank-line separated entries, staying under max_chars per chunk.\"\"\"\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\")\n",
    "    chunks, cur, total = [], [], 0\n",
    "    for block in s.split(\"\\n\\n\"):\n",
    "        block += \"\\n\\n\"\n",
    "        if cur and total + len(block) > max_chars:\n",
    "            chunks.append(\"\".join(cur))\n",
    "            cur, total = [], 0\n",
    "        cur.append(block)\n",
    "        total += len(block)\n",
    "    if cur:\n",
    "        chunks.append(\"\".join(cur))\n",
    "    return chunks\n",
    "\n",
    "def summarize_chunks(chunks: List[str], custom_prompt: str) -> List[str]:\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    system = \"Follow the user’s instructions exactly. Do not add extra sections beyond what they ask.\"\n",
    "    outputs = []\n",
    "    for i, ch in enumerate(chunks, 1):\n",
    "        prompt = (\n",
    "            custom_prompt\n",
    "            + f\"\\n\\nCHUNK {i}/{len(chunks)} — TWEETS START\\n<<<\\n{ch}\\n>>>\\n\"\n",
    "            + \"Return a concise markdown summary (headings + bullet points).\"\n",
    "        )\n",
    "        resp = model.generate_content([system, prompt])\n",
    "        outputs.append((resp.text or \"\").strip())\n",
    "    return outputs\n",
    "\n",
    "def final_synthesis(per_chunk: List[str], custom_prompt: str) -> str:\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    joined = \"\\n\\n--- CHUNK SPLIT ---\\n\\n\".join(per_chunk)\n",
    "    prompt = (\n",
    "        custom_prompt\n",
    "        + \"\\n\\nYou are given partial summaries of tweet batches. \"\n",
    "          \"Merge them into ONE well-structured Markdown document following the exact instructions above.\\n\\n\"\n",
    "          \"PARTIAL SUMMARIES START\\n<<<\\n\" + joined + \"\\n>>>\\n\"\n",
    "          \"Return ONLY the final markdown.\"\n",
    "    )\n",
    "    resp = model.generate_content(prompt)\n",
    "    return (resp.text or \"\").strip()\n",
    "\n",
    "def summarize_tweets_to_md(\n",
    "    tweets_path: str = \"financialjuice_last_hours.txt\",\n",
    "    output_md: str = \"summary.md\",\n",
    "    custom_prompt: str = \"\",\n",
    "    max_chars_per_chunk: int = 15000,\n",
    ") -> Tuple[str, int, int]:\n",
    "    raw = load_tweets(tweets_path)\n",
    "    if not raw:\n",
    "        raise ValueError(f\"Tweet file is empty: {tweets_path}\")\n",
    "\n",
    "    chunks = chunk_text(raw, max_chars=max_chars_per_chunk)\n",
    "    per_chunk = summarize_chunks(chunks, custom_prompt)\n",
    "    md = final_synthesis(per_chunk, custom_prompt)\n",
    "\n",
    "    pathlib.Path(output_md).write_text(md, encoding=\"utf-8\")\n",
    "    return output_md, len(raw), len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "948d82c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 50\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 20\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      1\u001b[39m custom_prompt = (\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Summarieze the following headlines into a concise Daily Macro & Markets Recap.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m out_file, n_chars, n_chunks = \u001b[43msummarize_tweets_to_md\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtweets_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUT_TXT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_md\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msummary.md\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_chars_per_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDone. Input chars: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_chars\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36msummarize_tweets_to_md\u001b[39m\u001b[34m(tweets_path, output_md, custom_prompt, max_chars_per_chunk)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTweet file is empty: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtweets_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     57\u001b[39m chunks = chunk_text(raw, max_chars=max_chars_per_chunk)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m per_chunk = \u001b[43msummarize_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m md = final_synthesis(per_chunk, custom_prompt)\n\u001b[32m     61\u001b[39m pathlib.Path(output_md).write_text(md, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36msummarize_chunks\u001b[39m\u001b[34m(chunks, custom_prompt)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks, \u001b[32m1\u001b[39m):\n\u001b[32m     25\u001b[39m     prompt = (\n\u001b[32m     26\u001b[39m         custom_prompt\n\u001b[32m     27\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCHUNK \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m — TWEETS START\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m<<<\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m>>>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33mReturn a concise markdown summary (headings + bullet points).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     resp = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     outputs.append((resp.text \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip())\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 50\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 20\n}\n]"
     ]
    }
   ],
   "source": [
    "custom_prompt = (\n",
    "    \"\"\"\n",
    "    Summarieze the following headlines into a concise Daily Macro & Markets Recap.\n",
    "    Divide the summary into clear sections by region and country, using headings and bullet points.\n",
    "    Group very very related news toghether and keep only the most relevant news for financial markets.\n",
    "    Keep the summary within 2 pages maximum, and max 5 bullet points per country.\n",
    "    Use the following sections, but remove those without relevant news:\n",
    "    1. Euro Area (Germany, France, Italy, Spain, Greece, Portugal, Belgium, Netherlands, Austria, Ireland, Finland)\n",
    "    2. Nordics (Sweden, Norway, Denmark, not Switzerland)\n",
    "    3. United Kingdom\n",
    "    4. Switzerland\n",
    "    5. North America (only United States and Canada)\n",
    "    6. APAC (only China, Japan, Australia, and New Zealand)\n",
    "    Make a subsection for each country for sections including many countries, and keep max 5 bullet points per country.\n",
    "    Use a headline line for each country (e.g., United States – Housing soft, Fed bias tilts dovish).\n",
    "    Divide every section with a horizontal line (---).\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "out_file, n_chars, n_chunks = summarize_tweets_to_md(\n",
    "    tweets_path=OUT_TXT,\n",
    "    output_md=\"summary.md\",\n",
    "    custom_prompt=custom_prompt,\n",
    "    max_chars_per_chunk=15000,\n",
    ")\n",
    "\n",
    "print(f\"Done. Input chars: {n_chars}, chunks: {n_chunks}\")\n",
    "print(f\"Saved -> {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01850aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
